{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sleeping_Hours</th>\n",
       "      <th>Habits</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Activity_Level</th>\n",
       "      <th>Mood_Swings</th>\n",
       "      <th>Diet_Quality</th>\n",
       "      <th>Water_Intake</th>\n",
       "      <th>Menstrual_Flow_Intensity</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Daily_Step_Count</th>\n",
       "      <th>Cycle_Regularity</th>\n",
       "      <th>Hormonal_Medication</th>\n",
       "      <th>Cycle_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1</td>\n",
       "      <td>22.51</td>\n",
       "      <td>11770</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3</td>\n",
       "      <td>26.00</td>\n",
       "      <td>4772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.37</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3</td>\n",
       "      <td>23.95</td>\n",
       "      <td>2987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2</td>\n",
       "      <td>21.27</td>\n",
       "      <td>10824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1</td>\n",
       "      <td>22.73</td>\n",
       "      <td>8875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>6.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3</td>\n",
       "      <td>21.99</td>\n",
       "      <td>3670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>8.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1</td>\n",
       "      <td>19.79</td>\n",
       "      <td>12541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4.01</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3</td>\n",
       "      <td>24.13</td>\n",
       "      <td>2873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>8.30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2</td>\n",
       "      <td>20.78</td>\n",
       "      <td>9994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sleeping_Hours  Habits  Stress_Level  Activity_Level  Mood_Swings  \\\n",
       "0               7.17       1             2               5            1   \n",
       "1               4.00       2             4               1            3   \n",
       "2               5.37       1             5               1            3   \n",
       "3               7.00       2             2               4            1   \n",
       "4               8.91       0             1               5            1   \n",
       "...              ...     ...           ...             ...          ...   \n",
       "4995            6.00       1             4               2            3   \n",
       "4996            8.92       1             2               5            1   \n",
       "4997            4.01       1             5               2            3   \n",
       "4998            4.00       2             4               2            3   \n",
       "4999            8.30       1             2               3            0   \n",
       "\n",
       "      Diet_Quality  Water_Intake  Menstrual_Flow_Intensity    BMI  \\\n",
       "0                4          2.53                         1  22.51   \n",
       "1                1          1.23                         3  26.00   \n",
       "2                2          1.92                         3  23.95   \n",
       "3                4          2.31                         2  21.27   \n",
       "4                3          3.73                         1  22.73   \n",
       "...            ...           ...                       ...    ...   \n",
       "4995             2          1.73                         3  21.99   \n",
       "4996             3          2.29                         1  19.79   \n",
       "4997             1          1.89                         3  24.13   \n",
       "4998             2          2.00                         3  22.70   \n",
       "4999             4          2.74                         2  20.78   \n",
       "\n",
       "      Daily_Step_Count  Cycle_Regularity  Hormonal_Medication  Cycle_Length  \n",
       "0                11770               1.0                    0          25.0  \n",
       "1                 4772               0.0                    0          38.6  \n",
       "2                 2987               0.0                    1          40.0  \n",
       "3                10824               1.0                    0          25.7  \n",
       "4                 8875               1.0                    0          25.0  \n",
       "...                ...               ...                  ...           ...  \n",
       "4995              3670               0.0                    0          35.0  \n",
       "4996             12541               1.0                    1          28.2  \n",
       "4997              2873               0.0                    0          35.6  \n",
       "4998              2638               0.0                    1          37.6  \n",
       "4999              9994               1.0                    0          26.6  \n",
       "\n",
       "[5000 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/next_cycle.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Cycle_Length'])\n",
    "y = df['Cycle_Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sleeping_Hours', 'Habits', 'Stress_Level', 'Activity_Level',\n",
       "       'Mood_Swings', 'Diet_Quality', 'Water_Intake',\n",
       "       'Menstrual_Flow_Intensity', 'BMI', 'Daily_Step_Count',\n",
       "       'Cycle_Regularity', 'Hormonal_Medication'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_lstm = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(30, activation='relu', input_shape=(X_train_lstm.shape[1], 1)))\n",
    "lstm.add(Dense(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 963.7156 - val_loss: 213.4158\n",
      "Epoch 2/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 172.0111 - val_loss: 61.5214\n",
      "Epoch 3/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.1243 - val_loss: 20.4496\n",
      "Epoch 4/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 17.5296 - val_loss: 7.3635\n",
      "Epoch 5/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6487 - val_loss: 4.6503\n",
      "Epoch 6/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0287 - val_loss: 4.1884\n",
      "Epoch 7/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5751 - val_loss: 3.9696\n",
      "Epoch 8/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.0118 - val_loss: 3.5547\n",
      "Epoch 9/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.9617 - val_loss: 3.3436\n",
      "Epoch 10/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7255 - val_loss: 3.1646\n",
      "Epoch 11/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7225 - val_loss: 3.4484\n",
      "Epoch 12/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.4262 - val_loss: 2.9620\n",
      "Epoch 13/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.3197 - val_loss: 3.0575\n",
      "Epoch 14/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.4074 - val_loss: 2.7450\n",
      "Epoch 15/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1414 - val_loss: 2.7509\n",
      "Epoch 16/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.1560 - val_loss: 2.6899\n",
      "Epoch 17/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.9901 - val_loss: 2.5777\n",
      "Epoch 18/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.9022 - val_loss: 2.5478\n",
      "Epoch 19/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9924 - val_loss: 3.1167\n",
      "Epoch 20/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.0230 - val_loss: 2.5581\n",
      "Epoch 21/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.8496 - val_loss: 2.4380\n",
      "Epoch 22/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8347 - val_loss: 2.3556\n",
      "Epoch 23/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7105 - val_loss: 2.3650\n",
      "Epoch 24/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7657 - val_loss: 2.4675\n",
      "Epoch 25/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6473 - val_loss: 2.5178\n",
      "Epoch 26/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7140 - val_loss: 2.7803\n",
      "Epoch 27/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5003 - val_loss: 2.5684\n",
      "Epoch 28/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6087 - val_loss: 2.3940\n",
      "Epoch 29/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4686 - val_loss: 2.1737\n",
      "Epoch 30/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9861 - val_loss: 2.4752\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the model...\")\n",
    "history = lstm.fit(X_train_lstm, y_train, epochs=30, batch_size=40, validation_data=(X_test_lstm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating the model...\")\n",
    "y_pred = lstm.predict(X_test_lstm)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.308467337544759\n",
      "Root Mean Squared Error (RMSE): 1.5732780276689438\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sleeping_Hours</th>\n",
       "      <th>Habits</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Activity_Level</th>\n",
       "      <th>Mood_Swings</th>\n",
       "      <th>Diet_Quality</th>\n",
       "      <th>Water_Intake</th>\n",
       "      <th>Menstrual_Flow_Intensity</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Daily_Step_Count</th>\n",
       "      <th>Cycle_Regularity</th>\n",
       "      <th>Hormonal_Medication</th>\n",
       "      <th>Cycle_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1</td>\n",
       "      <td>22.51</td>\n",
       "      <td>11770</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3</td>\n",
       "      <td>26.00</td>\n",
       "      <td>4772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.37</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3</td>\n",
       "      <td>23.95</td>\n",
       "      <td>2987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2</td>\n",
       "      <td>21.27</td>\n",
       "      <td>10824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1</td>\n",
       "      <td>22.73</td>\n",
       "      <td>8875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>6.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3</td>\n",
       "      <td>21.99</td>\n",
       "      <td>3670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>8.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1</td>\n",
       "      <td>19.79</td>\n",
       "      <td>12541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4.01</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3</td>\n",
       "      <td>24.13</td>\n",
       "      <td>2873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>8.30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2</td>\n",
       "      <td>20.78</td>\n",
       "      <td>9994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sleeping_Hours  Habits  Stress_Level  Activity_Level  Mood_Swings  \\\n",
       "0               7.17       1             2               5            1   \n",
       "1               4.00       2             4               1            3   \n",
       "2               5.37       1             5               1            3   \n",
       "3               7.00       2             2               4            1   \n",
       "4               8.91       0             1               5            1   \n",
       "...              ...     ...           ...             ...          ...   \n",
       "4995            6.00       1             4               2            3   \n",
       "4996            8.92       1             2               5            1   \n",
       "4997            4.01       1             5               2            3   \n",
       "4998            4.00       2             4               2            3   \n",
       "4999            8.30       1             2               3            0   \n",
       "\n",
       "      Diet_Quality  Water_Intake  Menstrual_Flow_Intensity    BMI  \\\n",
       "0                4          2.53                         1  22.51   \n",
       "1                1          1.23                         3  26.00   \n",
       "2                2          1.92                         3  23.95   \n",
       "3                4          2.31                         2  21.27   \n",
       "4                3          3.73                         1  22.73   \n",
       "...            ...           ...                       ...    ...   \n",
       "4995             2          1.73                         3  21.99   \n",
       "4996             3          2.29                         1  19.79   \n",
       "4997             1          1.89                         3  24.13   \n",
       "4998             2          2.00                         3  22.70   \n",
       "4999             4          2.74                         2  20.78   \n",
       "\n",
       "      Daily_Step_Count  Cycle_Regularity  Hormonal_Medication  Cycle_Length  \n",
       "0                11770               1.0                    0          25.0  \n",
       "1                 4772               0.0                    0          38.6  \n",
       "2                 2987               0.0                    1          40.0  \n",
       "3                10824               1.0                    0          25.7  \n",
       "4                 8875               1.0                    0          25.0  \n",
       "...                ...               ...                  ...           ...  \n",
       "4995              3670               0.0                    0          35.0  \n",
       "4996             12541               1.0                    1          28.2  \n",
       "4997              2873               0.0                    0          35.6  \n",
       "4998              2638               0.0                    1          37.6  \n",
       "4999              9994               1.0                    0          26.6  \n",
       "\n",
       "[5000 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: keras_tensor. Received: the structure of inputs=('*',)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "Prediction for Test Sample 1: 38.70\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Prediction for Test Sample 2: 38.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Prediction for Test Sample 3: 28.92\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Prediction for Test Sample 4: 38.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Prediction for Test Sample 5: 27.29\n"
     ]
    }
   ],
   "source": [
    "# Define the test samples\n",
    "test_samples = [\n",
    "    [4.00, 2, 4, 1, 3, 2, 1.10, 3, 27.82, 2363, 0.0, 1],\n",
    "    [3.20, 1, 5, 2, 4, 2, 1.20, 2, 25.40, 3180, 1.0, 0],\n",
    "    [6.50, 0, 2, 4, 1, 3, 1.80, 3, 26.50, 5600, 0.0, 0],\n",
    "    [5.00, 2, 4, 3, 2, 1, 1.50, 2, 28.00, 3900, 0.0, 1],\n",
    "    [7.80, 1, 3, 2, 3, 4, 1.60, 1, 24.20, 4500, 0.0, 0]\n",
    "]\n",
    "\n",
    "# Loop through each test sample, scale it, and make a prediction\n",
    "for idx, test in enumerate(test_samples):\n",
    "    # Scale the test sample\n",
    "    test_scaled = scaler.transform([test])  \n",
    "    \n",
    "    # Predict with the LSTM model\n",
    "    prediction = lstm.predict([test_scaled])\n",
    "    \n",
    "    # Print the prediction for each test sample\n",
    "    print(f\"Prediction for Test Sample {idx + 1}: {prediction[0][0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"next_cycle_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fdasfdsa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfdasfdsa\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fdasfdsa' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sleeping_Hours</th>\n",
       "      <th>Habits</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Activity_Level</th>\n",
       "      <th>Mood_Swings</th>\n",
       "      <th>Diet_Quality</th>\n",
       "      <th>Water_Intake</th>\n",
       "      <th>Menstrual_Flow_Intensity</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Daily_Step_Count</th>\n",
       "      <th>Cycle_Regularity</th>\n",
       "      <th>Hormonal_Medication</th>\n",
       "      <th>Cycle_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.37</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3</td>\n",
       "      <td>23.95</td>\n",
       "      <td>2987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.00</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3</td>\n",
       "      <td>29.49</td>\n",
       "      <td>6282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.59</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>23.36</td>\n",
       "      <td>2471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.88</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>30.00</td>\n",
       "      <td>6989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.56</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3</td>\n",
       "      <td>23.24</td>\n",
       "      <td>6374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>4.32</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3</td>\n",
       "      <td>23.16</td>\n",
       "      <td>3664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>3</td>\n",
       "      <td>27.82</td>\n",
       "      <td>2363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>5.40</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>24.85</td>\n",
       "      <td>2263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.42</td>\n",
       "      <td>3</td>\n",
       "      <td>22.28</td>\n",
       "      <td>4915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>4.07</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>24.32</td>\n",
       "      <td>6409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1324 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sleeping_Hours  Habits  Stress_Level  Activity_Level  Mood_Swings  \\\n",
       "2               5.37       1             5               1            3   \n",
       "14              6.00       2             5               1            4   \n",
       "15              5.59       1             4               2            3   \n",
       "21              5.88       2             4               2            3   \n",
       "24              4.56       1             5               2            3   \n",
       "...              ...     ...           ...             ...          ...   \n",
       "4981            4.32       1             5               1            4   \n",
       "4984            4.00       2             4               1            3   \n",
       "4992            5.40       2             4               1            3   \n",
       "4993            4.00       1             5               2            4   \n",
       "4994            4.07       1             5               1            4   \n",
       "\n",
       "      Diet_Quality  Water_Intake  Menstrual_Flow_Intensity    BMI  \\\n",
       "2                2          1.92                         3  23.95   \n",
       "14               2          1.73                         3  29.49   \n",
       "15               1          1.00                         3  23.36   \n",
       "21               1          1.00                         3  30.00   \n",
       "24               1          1.63                         3  23.24   \n",
       "...            ...           ...                       ...    ...   \n",
       "4981             1          1.18                         3  23.16   \n",
       "4984             2          1.10                         3  27.82   \n",
       "4992             1          1.00                         3  24.85   \n",
       "4993             2          1.42                         3  22.28   \n",
       "4994             2          1.00                         3  24.32   \n",
       "\n",
       "      Daily_Step_Count  Cycle_Regularity  Hormonal_Medication  Cycle_Length  \n",
       "2                 2987               0.0                    1          40.0  \n",
       "14                6282               0.0                    0          40.0  \n",
       "15                2471               0.0                    0          40.0  \n",
       "21                6989               0.0                    0          40.0  \n",
       "24                6374               0.0                    0          40.0  \n",
       "...                ...               ...                  ...           ...  \n",
       "4981              3664               0.0                    0          40.0  \n",
       "4984              2363               0.0                    1          40.0  \n",
       "4992              2263               0.0                    1          40.0  \n",
       "4993              4915               0.0                    0          40.0  \n",
       "4994              6409               0.0                    0          40.0  \n",
       "\n",
       "[1324 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Cycle_Length'] == 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Mean Squared Error: 1.77\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Model Mean Squared Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for Test Sample 1: 39.79\n",
      "Prediction for Test Sample 2: 35.67\n",
      "Prediction for Test Sample 3: 30.91\n",
      "Prediction for Test Sample 4: 32.65\n",
      "Prediction for Test Sample 5: 32.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for idx, test in enumerate(test_samples):\n",
    "    # Scale the test sample\n",
    "    test_scaled = scaler.transform([test])  \n",
    "    \n",
    "    # Predict with the LSTM model\n",
    "    prediction = rf_model.predict(test_scaled)\n",
    "    \n",
    "    \n",
    "    # Print the prediction for each test sample\n",
    "    print(f\"Prediction for Test Sample {idx + 1}: {prediction[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xgboost_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Mean Squared Error: 1.72\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgboost_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Model Mean Squared Error: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for Test Sample 1: 39.81\n",
      "Prediction for Test Sample 2: 38.72\n",
      "Prediction for Test Sample 3: 37.49\n",
      "Prediction for Test Sample 4: 38.36\n",
      "Prediction for Test Sample 5: 28.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for idx, test in enumerate(test_samples):\n",
    "    # Scale the test sample\n",
    "    test_scaled = scaler.transform([test])  # Use transform for test data, not fit_transform\n",
    "    \n",
    "    # Predict with the LSTM model\n",
    "    prediction = xgboost_model.predict(test_scaled)\n",
    "    \n",
    "    # Print the prediction for each test sample\n",
    "    print(f\"Prediction for Test Sample {idx + 1}: {prediction[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.6295850807110213\n",
      "R-squared: 0.9611495599934327\n",
      "Coefficients: [-0.01296001  0.01730967  1.51414914 -1.01499013 -0.04907311 -0.80918316\n",
      "  0.06871829  0.00621491  0.00547009 -0.01850296 -3.27639126  0.43288544]\n",
      "Intercept: 32.473057142857144\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) and R-squared (R2) score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Optionally: Print the coefficients of the model\n",
    "print(f\"Coefficients: {model.coef_}\")\n",
    "print(f\"Intercept: {model.intercept_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for Test Sample 1: 39.19\n",
      "Prediction for Test Sample 2: 31.82\n",
      "Prediction for Test Sample 3: 33.32\n",
      "Prediction for Test Sample 4: 38.36\n",
      "Prediction for Test Sample 5: 35.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for idx, test in enumerate(test_samples):\n",
    "    # Scale the test sample\n",
    "    test_scaled = scaler.transform([test])  # Use transform for test data, not fit_transform\n",
    "    \n",
    "    # Predict with the LSTM model\n",
    "    prediction = model.predict(test_scaled)\n",
    "    \n",
    "    # Print the prediction for each test sample\n",
    "    print(f\"Prediction for Test Sample {idx + 1}: {prediction[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "lstm.save(\"lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"rf_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"xg_boost.pkl\", \"wb\") as f:\n",
    "    pickle.dump(xgboost_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"linear_rg.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=True>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for Test Sample 1: 38.29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "Prediction for Test Sample 2: 29.00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Prediction for Test Sample 3: 39.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Prediction for Test Sample 4: 28.29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction for Test Sample 5: 37.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Prediction for Test Sample 6: 29.64\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Prediction for Test Sample 7: 38.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction for Test Sample 8: 37.38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction for Test Sample 9: 40.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sahit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Prediction for Test Sample 10: 27.35\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    [5.30, 1, 3, 2, 4, 1, 1.20, 3, 26.50, 4000, 0.0, 0],\n",
    "    [6.10, 0, 4, 3, 5, 2, 1.50, 2, 28.30, 5300, 1.0, 1],\n",
    "    [7.00, 2, 5, 1, 3, 3, 1.80, 1, 24.00, 6000, 0.0, 1],\n",
    "    [4.50, 1, 2, 4, 2, 4, 1.60, 3, 29.10, 3000, 1.0, 0],\n",
    "    [8.00, 2, 3, 2, 4, 2, 1.30, 2, 27.20, 5600, 0.0, 0],\n",
    "    [3.80, 0, 3, 1, 2, 1, 1.10, 3, 25.50, 3200, 1.0, 1],\n",
    "    [5.90, 1, 4, 2, 3, 3, 1.40, 2, 28.70, 5400, 0.0, 0],\n",
    "    [6.80, 0, 2, 3, 4, 4, 1.50, 1, 26.10, 4900, 0.0, 0],\n",
    "    [5.60, 2, 4, 1, 2, 2, 1.20, 2, 25.90, 4000, 0.0, 1],\n",
    "    [4.20, 0, 5, 4, 3, 1, 1.70, 3, 27.80, 3800, 1.0, 0]\n",
    "]\n",
    "\n",
    "for idx, test in enumerate(test_data):\n",
    "    # Scale the test sample\n",
    "    test_scaled = scaler.transform([test])  # Transform each sample individually\n",
    "    \n",
    "    # Reshape for LSTM input: [samples, time_steps, features\n",
    "    \n",
    "    # Predict with the LSTM model\n",
    "    prediction = lstm.predict([test_scaled])\n",
    "    \n",
    "    # Print the prediction for each test sample\n",
    "    print(f\"Prediction for Test Sample {idx + 1}: {prediction[0][0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
